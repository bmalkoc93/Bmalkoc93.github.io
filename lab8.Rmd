---
title: "Lab 8: Multilevel Models"
subtitle: <h4 style="font-style:normal">CRD 298 - Spatial Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
date: <h4 style="font-style:normal">February 27, 2019</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    code_folding: show
---


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

h1.title {
  font-weight: bold;
}

</style>
\

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The specific learning objectives in this lab are as follows:

1. Learn exploratory methods for understanding the multilevel structure of your data
2. Learn how to estimate explained variance at each level
3. Learn how to run a random intercept and slope multilevel model
4. Learn how to run spatial regime models

We will use multilevel models, which are also known as random effects (RE) and hierarchical linear models (HLM), to examine the census tract and metropolitan area demographic and socioeconomic predictors of median Hispanic household income in California neighborhoods.    According to some studies reported in the [popular press](https://www.npr.org/sections/codeswitch/2017/02/01/512522209/despite-turmoil-latinos-in-california-are-prospering), Hispanics in California are currently prospering.  Likely, this conclusion is not true across all of California - in some areas, Hispanics may be thriving, but others they are not. Let's see what the data tell us. Ready? Yes, of course.


<div style="margin-bottom:25px;">
</div>
## **Installing and loading packages**
\

We'll be using the following new packages in this lab 

```{r warning = FALSE, message = FALSE, eval = FALSE}
install.packages("lme4")
install.packages("lfe")
install.packages("sjstats")
install.packages("lmerTest")
install.packages("psych")
```

Load in the following packages, all of which we've covered in previous labs

```{r warning = FALSE, message = FALSE}
library(sf)
library(tidyverse)
library(tmap)
library(broom)
```

<div style="margin-bottom:25px;">
</div>
##**Bringing in the data**
\

We will be using the shape file ca_metro_tracts.shp. This file contains log median Hispanic household income in 2012-2016.  It also contains demographic and socioeconomic data from the 2012-2016 American Community Survey. The record layout for the shapefile's attribute table is located [here](https://raw.githubusercontent.com/crd230/data/master/ca_metro_tracts_record_layout.txt).  We will examine the association between log median Hispanic household income and tract-level concentrated disadvantage, percent of foreign-born residents, percent of Hispanic residents who own a home, percent of Hispanic residents who moved into the neighborhood within the past year and percent Hispanic.  Broader metropolitan area characteristics might also influence change in neighborhood-level Hispanic household income.  We will examine log median Hispanic household income, percent of the civilian labor force that is unemployed, and Hispanic/white and foreign-born/native-born segregation using the [Dissimilarity Index](http://enceladus.isr.umich.edu/race/seg.html).

I zipped up the files associated with the shapefile and uploaded it onto Github.  Download the file, unzip it, and bring it into R using the following code.

```{r warning = FALSE, message = FALSE, eval = FALSE}
setwd("insert your pathway here")
download.file(url = "https://raw.githubusercontent.com/crd230/data/master/ca_metro_tracts.zip", destfile = "ca_metro_tracts.zip")
unzip(zipfile = "ca_metro_tracts.zip")

ca.metro.tracts <- st_read("ca_metro_tracts.shp")
```

```{r warning = FALSE, message = FALSE, include = FALSE}
download.file(url = "https://raw.githubusercontent.com/crd230/data/master/ca_metro_tracts.zip", destfile = "ca_metro_tracts.zip")
unzip(zipfile = "ca_metro_tracts.zip")

ca.metro.tracts <- st_read("ca_metro_tracts.shp")
```

<div style="margin-bottom:25px;">
</div>
##**Exploratory Data Analysis**
\

Before running any explanatory model, you should descriptively examine your variables.  We can use the `describe()` function in the **psych** package to get a bunch of descriptive statistics for each of our variables.  We'll first need to load in the **psych** package and then set *ca.metro.tracts* as a non spatial data frame using the function `st_geometry()`.

```{r warning = FALSE, message = FALSE}
library(psych)

ca.metro.tracts.df <- ca.metro.tracts
st_geometry(ca.metro.tracts.df) <- NULL
```

```{r, warning = FALSE, message = FALSE}
ca.metro.tracts.df %>%
  select(lhinc, phisp, concd, pfb, phhown, phmov, lhincm, punempm, hwdis, fbdis) %>%
  describe()
```

It looks like the tract-level mean log Hispanic median household income is 10.96, which is $57,526.44 when exponentiated.

You can also examine a correlation matrix to gauge associations between variables. We exclude the metro level characteristics because tracts within metros will artificially inflate the correlations.

```{r, warning = FALSE, message = FALSE}
corrMat <- ca.metro.tracts.df %>% select(lhinc, concd, phisp, pfb, phhown, phmov) %>%
  cor()
corrMat
```

We can also conduct the exploratory spatial data analysis techniques discussed in [Lab 5](https://crd230.github.io/lab5.html) to examine underlying spatial patterns in the data.  For now, let's just map the dependent variable *lhinc*

```{r, message = FALSE}
tm_shape(ca.metro.tracts) + tm_polygons(col = "lhinc", style = "quantile", palette="Blues")
```


<div style="margin-bottom:25px;">
</div>
##**Single-level regression**
\

Let's fit a basic single-level regression model using the `lm()` function. Regress tract-level log Hispanic median household income on our tract-level variables concentrated disadvantage, percent Hispanic home ownership, percent foreign born, Hispanic mobility rate, and percent Hispanic.

```{r, warning = FALSE, message = FALSE}
single.model1 <- lm(lhinc ~ concd   + phhown + pfb  +phmov + phisp, data = ca.metro.tracts)
```

A tidy table of results

```{r}
tidy(single.model1)
```

It  appears that concentrated disadvantage, percent Hispanic, and the 1-year Hispanic mobility rates are associated with a lower median Hispanic household income whereas percent Hispanic home ownership and percent foreign-born are associated with a higher Hispanic income.  

Let's now incorporate the metro level characteristics.

```{r, warning = FALSE, message = FALSE}
single.model2 <- lm(lhinc ~ concd  +pfb + phhown   +phmov + phisp + lhincm + punempm + 
                      hwdis + fbdis, data = ca.metro.tracts)
tidy(single.model2)
```

We find that the percent foreign born and Hispanic mobility rate coefficients flip - the former is now associated with a lower Hispanic household income whereas the latter is associated with a higher income.  The metro level unemployment rate, log Hispanic household income and Hispanic/white segregation are associated with higher tract-level Hispanic household income whereas foreign-born/native-born segregation is associated with a lower income.

<div style="margin-bottom:25px;">
</div>
##**Fixed effects regression**
\

A metro fixed effects regression specification controls for all metro-level characteristics that may be confounding the relationship between tract-level variables and the change in Hispanic household income. It also controls for spatial autocorrelation between tracts within metropolitan areas.

We can run a fixed effects regression using the `lm()` function by including the metro indicator as a factor variable on the right hand side of the equation. A factor variable treats the values as categories, such as male and female for gender or college educated, high school only educated, and non high school educated for educational attainment.  Use the function `factor()` on the metro indicators *GEOIDm* within the `lm()` function.

```{r, warning = FALSE, message = FALSE}
fe.int.model1 <- lm(lhinc ~ concd  +pfb + phhown   +phmov + phisp + factor(GEOIDm),
     data = ca.metro.tracts)
tidy(fe.int.model1)
```

R automatically removes one of the levels, in this case the metropolitan area with a *GEOIDm* equal to 12540. The group removed is known as the reference group or category, and the *factor(GEOIDm)* coefficient for each metropolitan area is comparing the mean *lhinc* relative to the reference group.  For example, the *factor(GEOIDm)* coefficient for metropolitan area 17020 is -0.311616, which means that the log Hispanic median household income for metro area 17020 is 0.311616 lower than the log Hispanic median household income for metro area 12540.

You'll notice the bottom of the tibble produced by the `lm()` function above indicates that there are 21 more rows of results, which provide coefficients for the rest of the California metropolitan areas. We can use the function `felm()` to run a fixed effects model with the fixed effects on the metro areas suppressed from the summary.  We specify *GEOIDm* as  a factor, but specify it as a fixed effect using the `|`  symbol at the end of the equation.

```{r, warning = FALSE, message = FALSE}
library(lfe)
fe.int.model2 <- felm(lhinc ~ concd  +pfb + phhown   +phmov + phisp | factor(GEOIDm),
     data = ca.metro.tracts)
tidy(fe.int.model2)
```

You'll notice the table of results suppresses the fixed effect coefficients, allowing you to create publication ready tables (fixed effects are typically not reported).

We find that that the FE results do not broadly diverge from the single level regression results. 


<div style="margin-bottom:25px;">
</div>
##**Multilevel regression**
\

A disadvantage of the fixed effects specification is that we can't include any variables measured at the metropolitan area level - they are absorbed by the metro fixed effects. We see that when we try to include the metro area characteristics into the `felm()` function.

```{r, message = FALSE}
felm(lhinc ~ concd  +pfb + phhown   +phmov + phisp 
              +lhincm + punempm + hwdis + fbdis | factor(GEOIDm),
     data = ca.metro.tracts)
```

The warning tells us something bad happened. And we see that with *NaN* values reported for the metro level coefficients.

A fixed effects regression is fine if you are not concerned with understanding the association between metro-level characteristics and the lower level (census tract) dependent variable.  In fact, it's a model with less assumptions compared to a multilevel model.  But, what if we are interested in examining metro level predictors, but also control for the correlation between neighborhoods within metro areas? That's where multilevel models come in.

Before estimating a multilevel model, check the sample size of level 2 units (metros)

```{r, warning = FALSE, message = FALSE}
length(table(ca.metro.tracts$metro))
```

Although not as important, check if there is a large number of level 1 units (tracts) within each level 2 unit (metro)

```{r, warning = FALSE, message = FALSE}
nunits <-ca.metro.tracts %>%
  group_by(metro) %>%
  summarize("# tracts" = n())
st_geometry(nunits) <- NULL
as.data.frame(nunits)
```

You should also check if there is variation in the dependent variable between- and within- metropolitan areas.  We can do this descriptively using a boxplot.

```{r, warning = FALSE, message = FALSE}
ggplot(ca.metro.tracts) +
  geom_boxplot(mapping = aes(x = as.factor(GEOIDm), y = lhinc)) + ylab("Log median Hispanic household income") + xlab("Metropolitan area") + theme(axis.text.x=element_blank())
```

Two things: (1) there appears to be within-metro variation in household income as indicated by the size of the boxes; (2) there appears to be between-metro variation as indicated by the variation in the means across metros.

We can formally check for variation across metropolitan areas using a basic ANOVA that tests differences in the means across metros. Remember, if all metros are basically the same, there's no use running a multi-level model - in other words, all the "action" is happening between tracts.

```{r, warning = FALSE, message = FALSE}
fit.test<-lm(lhinc~factor(GEOIDm), data=ca.metro.tracts)
#Global F test for equality of means across the metros 
anova(fit.test)
```

Yes! The statistically significant F statistic indicates that the means are not equal (null hypothesis is means are equal).  Note that a multilevel model is a regression model, so it still needs to meet the other regression assumptions outlined in Week 6.

<div style="margin-bottom:25px;">
</div>
###**Variation explained**
\

Let's first run a null multilevel model.  Doing so will give us estimates of the amount and percent of variation explained at each level - tract and metropolitan area.  To run a multilevel model, we'll use the `lmer()` function, which is a part of the **lme4** package. You'll also need to load in the package  **lmerTest** to attach p-value results to your coefficients.

```{r, warning = FALSE, message = FALSE}
library(lme4)
library(lmerTest)
```

Next, run an empty  random intercept model, which does not include any tract or metropolitan area level characteristics.

```{r, warning = FALSE, message = FALSE}
re.int.model1 <- lmer(lhinc~ (1|GEOIDm), data=ca.metro.tracts)
summary(re.int.model1, correlation = FALSE)
```

I use `correlation = FALSE` in the `summary()` function to suppress the *Correlation of Fixed Effects* results, which frankly I have a hard time interpreting. The `lmer` function's arguments take on a similar form as `lm()` except the use of `(1|GEOIDm)`. The argument `(1|GEOIDm)` indicates the random effects of the equation, including the second level (metropolitan area) variation.  The following table shows how to specify the different multilevel models using this `( | )` format.  

```{r include = FALSE, message = FALSE, warning = FALSE}
dt1<-c("(1|group)", "(0+x|group)", "(-1+x|group)", "(x|group)", "(1|group1) + (1|group1:group2)")
dt2<-c("Random intercept", "Random slope", "Random slope", "Random int and slope", "Random int for group1 and group2")
dt<-as_tibble(data.frame(Argument = dt1, Model = dt2))
library(knitr)
library(kableExtra)
```

```{r echo=  FALSE, warning = FALSE, message = FALSE}
kable(dt) %>%
    kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```

There are other specifications that deal with different types of nesting structures.  You'll explore one of these alternative nesting structures in homework 4.

Going back to our output of results, the results under the "Random effects" heading provide the variation at each level - level 1 tract (*Residual*) and level 2 metro area (*GEOIDm*).  We actually want the percent of variation explained, so we have to divide the RE of *GEOIDm* by the total variation (*Residual* + *GEOIDm*).  We can do this by using the `re_var()` function, which extracts the random effects of a saved multilevel object.  This function is in the **sjstats** package, which we'll need to load.

```{r, warning = FALSE, message = FALSE}
library(sjstats)
var.est<-re_var(re.int.model1)
var.est[2]/sum(var.est)
```

The proportion explained at each level is known as the intra-class correlation (ICC). The `icc()` function in the **sjstats** package calculates the ICC directly for the higher level(s).

```{r, warning = FALSE, message = FALSE}
icc(re.int.model1)
```

We find that the proportion of variation in median Hispanic Household income explained by differences across metro areas is 16%. The rest is explained by census tracts and potentially other levels.

Note that our outcome *lhinc* is continuous.  If we have a non-continuous outcome such as a count or categorical variable, we use the `glmer()` function, and specify the outcome distribution using the `family` argument.  For example, if you have a binary outcome, specify `family = binomial`, which runs a multilevel logit regression model.  

<div style="margin-bottom:25px;">
</div>
###**Random intercepts with covariates**
\

An empty random intercept model gives us percent variation explained at each level.  Let's now add covariates to try to find which specific variables might explain variation in the outcome.  First, let's add the tract-level variables

```{r, warning = FALSE, message = FALSE}
re.int.model2 <- lmer(lhinc~ concd  +pfb + phhown   +phmov + phisp 
              +  (1|GEOIDm), data=ca.metro.tracts)
summary(re.int.model2, correlation = FALSE)
```

If you are annoyed by the results shown in [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation), use the `scipen=alpha` argument in the `options()` command, where `alpha`  is the maximum number of digits for the result to be still expressed in fixed notation.

```{r, warning = FALSE, message = FALSE}
options(scipen=1)
summary(re.int.model2, correlation = FALSE)
```

Now include the metropolitan area characteristics.

```{r, warning = FALSE, message = FALSE}
re.int.model3 <- lmer(lhinc~ concd  +pfb + phhown   +phmov + phisp 
              +lhincm + punempm + hwdis + fbdis + (1|GEOIDm), data=ca.metro.tracts)
summary(re.int.model3, correlation = FALSE)
```

The tract-level coefficients don't change much in terms of their effect sizes and statistical significance compared to the single and fixed effects regression results.  However, we do see significant changes in the metro-level characteristics compared to the single-level results.  The direction of the effects do not change, but foreign-born segregation is now significant at the 5 percent level.  Moreover, the effect sizes are much larger in the multilevel model.  How would you explain these changes?

<div style="margin-bottom:25px;">
</div>
###**Random coefficients**
\

We might be interested in determining whether the effects of certain tract-level variables vary across metropolitan area.  Here, we run a random coefficient or slope model.  First, run a random coefficient model for *phhown* without a random intercept.

```{r, warning = FALSE, message = FALSE}
re.slope.model1 <- lmer(lhinc~ concd  +pfb + phhown   +phmov  + phisp 
              +lhincm + punempm + hwdis + fbdis + (0+phhown|GEOIDm), data=ca.metro.tracts)
summary(re.slope.model1, correlation = FALSE)
```

The results under the *Random effects* section tells us that the random slope for *phhown* has a variance of 0.01032 - that is, the amount of variability in the slope of *phhown* across metro areas is 0.01032.  How do we know whether this variability is statistically different from 0?  We can use the function `ranova()` in the **lmerTest** package, which uses a Chi-square test to test against the null of variance equal to 0.  


Plug in your saved random slope model above into `ranova()` 

```{r warning = FALSE, message = FALSE}
ranova(re.slope.model1)
```

We can add a random intercept by replacing the `0` in `( | )` by 1.

```{r, warning = FALSE, message = FALSE}
re.int.slope.model <- lmer(lhinc~ concd  +pfb + phhown   +phmov  + phisp 
              +lhincm + punempm + hwdis + fbdis + (1+phhown+pfb|GEOIDm), data=ca.metro.tracts)
summary(re.int.slope.model, correlation = FALSE)
```

And test whether variation in the slopes and intercept is significant from 0.

```{r warning = FALSE, message = FALSE}
ranova(re.int.slope.model)
```

We can add random slopes to other variables.  For example, we found that percent foreign born is positively associated with log Hispanic median household income.  Does that vary across metro areas?

```{r, warning = FALSE, message = FALSE}
re.int.slope.model2 <- lmer(lhinc~ concd  +pfb + phhown   +phmov  + phisp 
              +lhincm + punempm + hwdis + fbdis + (1+phhown+pfb|GEOIDm), 
              data=ca.metro.tracts)
ranova(re.int.slope.model2)
```


<div style="margin-bottom:25px;">
</div>
###**Visualizing differences**
\

We can visualize the differences between the single level, random intercept, random coefficient, and random intercept and coefficient models by extracting the predicted values of log Hispanic median household income from each model.  This will help fortify how exactly these different approaches are modelling the outcome.  For simplicity's sake, we'll fit models only examining the relationship between percent Hispanic home ownership and log Hispanic median income. First, fit the models

```{r, warning = FALSE, message = FALSE}
ols <- lm(lhinc ~ phhown, data = ca.metro.tracts)
reint <- lmer(lhinc~ phhown  + (1|GEOIDm), data=ca.metro.tracts)
reslope <- lmer(lhinc~ (0+phhown|GEOIDm), data=ca.metro.tracts)
reintslope <- lmer(lhinc~  (1+phhown|GEOIDm), data=ca.metro.tracts)
```

Second, we extract the predicted or fitted log Hispanic median household income using the `fitted()` function.  Let's save these predictions into our data set *ca.metro.tracts* 

```{r, warning = FALSE, message = FALSE}
ca.metro.tracts$PooledPredictions <- fitted(ols)
ca.metro.tracts$VaryingInterceptPredictions <- fitted(reint)
ca.metro.tracts$VaryingSlopePredictions <- fitted(reslope)
ca.metro.tracts$InteractionPredictions <- fitted(reintslope)
```

Next, we plot the random intercept predictions compared to the single level model predictions 

```{r, warning = FALSE, message = FALSE}
ggplot(ca.metro.tracts) +
    geom_line(aes(x = phhown, y = PooledPredictions), color = "darkgrey") +
    geom_line(aes(x = phhown, y = VaryingInterceptPredictions), color = "blue") +
    #geom_line(aes(x = phhown, y = VaryingSlopePredictions), color = "red") +
    #geom_line(aes(x = phhown, y = InteractionPredictions), color = "black") +
    facet_wrap(~GEOIDm) +
    theme_bw()
```

Do the plots jibe with what you thought these models are doing?

Next, varying slope for *phhown* vs. single level 

```{r, warning = FALSE, message = FALSE}
ggplot(ca.metro.tracts) +
    geom_line(aes(x = phhown, y = PooledPredictions), color = "darkgrey") +
    #geom_line(aes(x = phhown, y = VaryingInterceptPredictions), color = "blue") +
    geom_line(aes(x = phhown, y = VaryingSlopePredictions), color = "red") +
    #geom_line(aes(x = phhown, y = InteractionPredictions), color = "black") +
    facet_wrap(~GEOIDm) +
    theme_bw()
```

Finally, the varying slope and intercept vs single level

```{r, warning = FALSE, message = FALSE}
ggplot(ca.metro.tracts) +
    geom_line(aes(x = phhown, y = PooledPredictions), color = "darkgrey") +
    #geom_line(aes(x = phhown, y = VaryingInterceptPredictions), color = "blue") +
    #geom_line(aes(x = phhown, y = VaryingSlopePredictions), color = "red") +
    geom_line(aes(x = phhown, y = InteractionPredictions), color = "black") +
    facet_wrap(~GEOIDm) +
    theme_bw()
```

Based on the random slope + intercept model, which metro areas exhibit a *phhown* slope that considerably deviates from the mean? Which metro areas do not?

<div style="margin-bottom:25px;">
</div>
##**Model selection**
\

Which model do we choose - Single level, Multilevel with a random intercept, Multilevel with a random slope, Multilevel with a random slope and intercept? The specific hypothesis you are interested in testing and the theory backing up that hypothesis should guide you towards which model to ultimately choose.  But, you can run some likelihood ratio tests, which are based on model fit using the log likelihood to make comparisons, to make some comparisons.

<div style="margin-bottom:25px;">
</div>
###**Single level vs. Multilevel**
\

The `ranova()` function allows us to compare multilevel models with single level regressions.  We already used `ranova()` above to test whether the variance of the random slope is statistically different from a null of 0.  This test is the same thing as comparing model fit for a random slope model compared to a regular single level regression. We test the random intercept model against the single level as follows.

```{r, warning = FALSE, message = FALSE}
ranova(re.int.model3)
```

What about the random slope + intercept model?

```{r, warning = FALSE, message = FALSE}
ranova(re.int.slope.model)
```

The results actually compare models with random slopes for *phhown* and *pfb* separately.  To test the combined model against a single level model, use the `reduce.terms = FALSE` argument

```{r, warning = FALSE, message = FALSE}
ranova(re.int.slope.model, reduce.terms = FALSE)
```

<div style="margin-bottom:25px;">
</div>
###**Random intercept vs. Random slope**
\

Random intercept and slope models are nested, which means we can use a basic ANOVA to make comparisons between the two. We do this by using the `anova()` function, which we also used when we made model comparisons between spatial regression models in [Week 7 Lab](https://crd230.github.io/lab7.html#spatial_durbin_model).  

The null will always be the simpler model, with a random intercept only model being the simplest among the multilevel flavors.  For example, testing model fit between a random intercept only model and a random slope on *phhown* yields :

```{r, warning = FALSE, message = FALSE}
anova(re.int.model3, re.slope.model1)
```

Random intercept only vs Random intercept and random slopes for *phhown* and *pfb*?

```{r, warning = FALSE, message = FALSE}
anova(re.int.model3, re.int.slope.model)
```

The difference between `ranova()` and `anova()` is that the latter generalizes what the former is doing. `ranova()` tests against the null of a single level model.  `anova()` allows you test across all nested models.

We can also rely on our new best friend the Akaike Information Criterion (AIC).  Remember, AIC is related to deviance. Deviance is bad. So, the lower the deviance, the better, which means the lower the AIC, the better the fit.  We can use the AIC to even compare across fixed and random effects models.

```{r, warning = FALSE, message = FALSE}
#Save AIC values
AICs<-c(AIC(single.model2),AIC(fe.int.model1), AIC(re.int.model3), AIC(re.slope.model1), AIC(re.int.slope.model))

#plot the AICs
plot(AICs, type="l", lwd=1.5, xaxt="n", xlab="")
axis(1, at=1:5,labels=F) #6= number of models
labels<-c("OLS", "FE","RE-Int", "RE-Slope","RE-Int/Slope" )
text(1:5, par("usr")[3]-.25, srt=45, adj=1, labels=labels, xpd=T)
mtext(side=1, text="Model Specification", line=3)
#circle the model with the lowest AIC
symbols(x= which.min(AICs), y=AICs[which.min(AICs)], circles=1, fg=2,lwd=2,add=T)
```

The random intercept and slope model seems to be the best fitting.  But, once again, what were trying to do with an FE model is very different with what we are trying to accomplish with a multilevel model. What is your hypothesis, what is your theoretical framework, what pathways are you interested in...

<div style="margin-bottom:25px;">
</div>
##**Spatial Regime Model**
\

In a spatial regime model, we stratify the data by either a known fixed quality, such as the metropolitan area in which a tract is located, or perhaps some other socio-demographic or socio-economic variable. We then fit separate regression models for each regime.  You can do this through a split-sample approach whereby  you subset your data set into different regimes and run models for each regime.  You can also run a fully-interacted model.  To do the latter in R, you'll have to specify  *GEOIDm* as a factor and use the following format in the `lm()` function

```{r}
fit.metro.regime<-lm(lhinc~ factor(GEOIDm)/(concd  +pfb + phhown   +phmov + phisp), data = ca.metro.tracts)
```

The `factor(GEOIDm)/( ... )` argument tells R to interact the variable *factor(GEOIDm)* with all the variables contained within the parentheses after `/`.  Let's examine the results

```{r results = "hide"}
summary(fit.metro.regime)
```

oooff. The results show a coefficient for each variable and metro area combination. 

In the models above, we specified the regimes based on metro area affiliation. We can also establish regimes based on a demographic characteristic, say poverty:

```{r}
ca.metro.tracts <- mutate(ca.metro.tracts, pov_group = cut(ppov, breaks = quantile(ppov,
p=c(0, .3, .6, 1)), include.lowest = T))
```

Here, we separated counties into three poverty regimes: Low poverty (bottom 30%), medium
poverty (Between the 30th and 60th percentiles), and high poverty (above the 60th percentile).
Let's map these groups

```{r eval = FALSE}
tmap_mode("view")
tm_shape(ca.metro.tracts) + tm_polygons(col = "pov_group", style = "cat", palette="Blues")
```

We then run a fully interacted regression model with *pov_group* as our factor

```{r}
fit.pov.regime<-lm(lhinc~ pov_group/(concd  +pfb + phhown   +phmov + phisp), data = ca.metro.tracts)

summary(fit.pov.regime)
```

We find some differences in the effects of various tract characteristics across poverty regimes.  For example, percent foreign born is positively associated with log Hispanic median household income for mid and high poverty regimes, but not in low poverty areas.

<div style="margin-bottom:25px;">
</div>
##**Geographically Weighted Regression**
\

Another approach to modelling spatial heterogeneity is to run a Geographically Weighted Regression (GWR).  Here, you are running a regression for every location (level 1 using multilevel model parlance) in your study  area.  If you have 8,000 census tracts, you will be running 8,000 regressions.  I am not a huge fan of GWR, largely because of problems related to [multicollinearity](https://link.springer.com/article/10.1007/s10109-005-0155-6) and [multiple testing](https://onlinelibrary.wiley.com/doi/abs/10.1111/gean.12084).  There has been work addressing these issues, specifically [here](https://link.springer.com/article/10.1007/s10109-016-0239-5) and [here](https://journals.sagepub.com/doi/abs/10.1068/a40256?casa_token=P9JzrNS3WW8AAAAA:Ds4yaPVa2e32OnH0Hwr7DjRLrIA0twj14mCSc9zGhQlBeVCtjMQlLxa765YqjzPlgk0K0NtyTofGm4k).  My judgement of the method is that it is useful for exploratory analysis to visualize differences in coefficient sizes across your study area.  Therefore, I would categorize GWR as an Exploratory Spatial Data Analysis technique such as the local Getis-Ord.  Combined with statistical methods like the Lasso (see article above) or ridge regression, GWR can also be a useful [predictive or interpolation tool](https://www.sciencedirect.com/science/article/abs/pii/S0143622813000878).

I provide a [mini-lab](https://crd230.github.io/gwr.html) if you want to learn more about GWR and how to do it in R.  You can find one of the seminal pieces on GWR [here](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1538-4632.1996.tb00936.x). 


***


Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)



