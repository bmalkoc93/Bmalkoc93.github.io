---
title: 'Lab 1: Working with the United States Census'
subtitle: <h4 style="font-style:normal">CRD 298 - Spatial Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
date: <h4 style="font-style:normal">January 9, 2019</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    code_folding: show
---


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
}

</style>
\

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this guide you will learn how to download, clean, manage and summarize United States Census data using R. The goal, however, is not to just gain exposure to Census data, but to also acquire skills in data acquisition, management and presentation using R.  You will be working with data on California census tracts. The objectives of the guide are as follows

1. Download Census data using their API
2. Read data into R
3. Learn data wrangling functions
4. Summarize data using descriptive statistics and graphs

This lab guide follows closely and supplements the material presented in Chapters 1, 3, 5, 8-10, 14 and 22 in the textbook [R for Data Science](http://r4ds.had.co.nz/index.html) (RDS).

<div style="margin-bottom:25px;">
</div>
## **Open up a new R Markdown file**
\

When going through lab guides, I would recommend not copying and pasting code directly into the R Console, but saving and running it from either an R Script or Markdown file. You can use either one, but because you'll be using R Markdown for assignments, use R Markdown first to get you some practice. The code is in **your** document, so you can add explanatory text or supplement the guide's code with your own code.  

To open a new R Markdown file, click on *File* at the top menu in RStudio, select *New File*, and then *R Markdown*. A window should pop up. In that window, for *Title*, put in "Lab 1".  For *Author*, put your name. Leave the HTML radio button clicked, and select OK.  A new R Markdown file should pop up in the top left window.  Don't change anything inside the YAML (the stuff at the top in between the `---`).  Also keep the grey chunk after the YAML.

````
`r ''````{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
````

Delete everything else. Save this file (File -> Save) in an appropriate folder.  If you are using your laptop for this guide, it's best to set up a clean and efficient file management structure like we described in lecture and outlined [here]().  For example, below is where I would save this file in my Mac laptop (I named the file "Lab1").  Save all other files used in this lab in this same folder. Now your R Markdown file is ready for Lab!  

<center>
![This is what file organization looks like](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/lab1fig1.png)

</center>


<div style="margin-bottom:25px;">
</div>
## **Downloading Census Data**
\

The Census is the most important source of community data in the United States. There are two ways to bring Census data into R. 

<div style="margin-bottom:25px;">
</div>
### **Using the Census API**
\

The first way is to bring it directly into R using the [Census Application Program Interface  (API)](https://www.census.gov/data/developers/guidance/api-user-guide.What_is_the_API.html). An API allows for direct requests for data in machine-readable form.  That is, rather than you having to navigate to some website, scroll around to find a dataset, download that dataset once you find it, save that data onto your hard drive, and then bring the data into R, you just tell R to retrieve data directly from that website using one or two lines of code.  In order to download from the Census API, you will need to load in the **tidyverse** package, which we covered in [Lab 0](https://crd230.github.io/lab0.html).  You will also need to install and load in the **tidycensus** package using the `install.packages()` and `library()` functions.  

```{r message = FALSE, warning=FALSE, eval = FALSE}
install.packages("tidycensus")
library(tidyverse)
library(tidycensus)
```

```{r message = FALSE, warning=FALSE, results="hide", include = FALSE}
library(tidyverse)
library(tidycensus)
```

In order to directly download data from the Census API, you need a key.  You can sign up for a free key [here](http://api.census.gov/data/key_signup.html), which you should have already done before the lab. Type your key in quotes using the `census_api_key()` command


```{r include=FALSE, warning=FALSE, results="hide"}
census_api_key("b81d373d6e785ecbc489de1fc862aef424d0a63a")
```

```{r eval=FALSE, warning=FALSE, results="hide"}
census_api_key("YOUR API KEY GOES HERE")
```

The function for downloading American Community Survey (ACS) Census data is `get_acs()`. The command for downloading decennial Census data is `get_decennial()`.  Getting variables using the Census API requires knowing the variable ID - and there are thousands of variables (and thus thousands of IDs) across the different Census files. To rapidly search for variables, use the commands `load_variables()` and `View()`. Because we'll be using the ACS in this guide, let's check the variables in the most recent 5-year ACS (2012-2016)

```{r warning = FALSE}
v16 <- load_variables(2016, "acs5", cache = TRUE)
View(v16)
```

A window in the top left of your RStudio interface should have popped up showing you a record layout of the 2012-16 ACS.  To search for specific data, select "Filter"" located at the top left of this window and use the search boxes that pop up.  For example, type in "Hispanic" in the box under "Label".  You should see at the top of the list the first set of variables we'll want to download - race/ethnicity.  Let's extract that data and total population for California census tracts using the `get_acs()` command

```{r message = FALSE, warning = FALSE}
ca <- get_acs(geography = "tract", 
              year = 2016,
              variables = c(tpopr = "B03002_001", 
                            nhwhite = "B03002_003", nhblk = "B03002_004", 
                            nhasn = "B03002_006", hisp = "B03002_012"), 
              state = "CA",
              survey = "acs5")
```

In the above code, we specified the following arguments

* `geography`: The leve of geography we want that data in - in our case, tract.  Other geographic options can be found [here](https://walkerke.github.io/tidycensus/articles/basic-usage.html#geography-in-tidycensus). 
* `year`: The end year of the data (because we want 2012-2016, we use 2016).
* `variables`: The variables we want to bring in as specified in a vector you create using the function `c()`. Note that we created variable names of our own (e.g. "nhwhite") and we put the ACS IDs in quotes. ("B03002_003"). Had we not done this, the variable names will come in as they are named in the ACS, which is not all that descriptive.
* `state`: We can filter the tracts to those in a specific case, here it is "CA" - if we don't specify this, we get all tracts in the United States.
* `survey`: The specific Census survey were extracting data from.  We want 5-year American Community Surveym so we specify "acs5" - remember that the ACS comes in 1-, 3-, and 5-year varieties.  

Type in `? get_acs()` to see the full list of options. If you type in *ca* in your console, you should see a tibble pop up with the variables we selected. Cool, right?

```{r}
ca
```

<div style="margin-bottom:25px;">
</div>
### **Downloading from an online source**
\

The other way to get Census data is to download them directly from the web.  There are several websites where you can download Census data including [Social Explorer](https://www.socialexplorer.com/), which as UC Davis affiliates we have free access to, and [Fact Finder](https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml), which is free for everyone.  The site we used in lecture is the [National Historical Geographic Information System (NHGIS)](https://www.nhgis.org/).  You may choose to use NHGIS (or any of the other sources listed above) over the API because it is more user friendly in terms of selecting variables.  I've uploaded a brief step-by-step tutorial for downloading NHGIS data [here](http://crd230.github.io/nhgis.html).

To save us time, I've uploaded an NHGIS csv file on GitHub for you to use in this lab. Download the file from [here](https://raw.githubusercontent.com/crd230/data/master/nhgis0106_ds225_20165_2016_tract.csv) and save it into the same folder where your Lab 1 R Markdown file resides.  The file contains census tract-level data on median household income for all tracts in the United States. The record layout/codebook for the file can be found [here](https://raw.githubusercontent.com/crd230/data/master/nhgis0106_ds225_20165_2016_tract_codebook.txt).  

<div style="margin-bottom:25px;">
</div>
## **Reading in data**
\

Most of the data files you will encounter are comma-delimited (or comma-separated) files, which have `.csv` extensions.  Comma-delimted means that columns are separated by commas.  The file from NHGIS is a `.csv` file.  To import this file in R, use the `read_csv()` command, which is found in the **tidyverse** package. 

```{r warning=FALSE, results="hide", message=FALSE, echo=FALSE}
nhgisfile1 <- read_csv("https://raw.githubusercontent.com/crd230/data/master/nhgis0106_ds225_20165_2016_tract.csv")
```

To read in the csv file you downloaded from NHGIS, first make sure that R is pointed to the folder you saved your data into.  Type in `getwd()` to find out the current directory and `setwd("directory name")` to set the directory to the folder containing the data.  For me, the NHGIS file is located in the folder shown in Figure 1.

<center>
![Figure 1: Direct R to where your data reside.](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/lab1fig2.png)

</center>

I type in the following command to set the directory to the folder containing my data on my Mac laptop

```{r, eval = FALSE}
setwd("/Users/noli/Documents/Classes/CRD 298/Lab/Lab 1")
```

Note that on a Windows system, the file pathway may be indicated with a back slash `\`.  R doesnt like that because it thinks of a single backslash as an escape character.  Use instead two back slahses `\\` or a forward slash `/`.  Use `read_csv()` and plug in the name of the file in quotes inside parentheses  

```{r, eval = FALSE}
nhgisfile1 <- read_csv("nhgis0106_ds225_20165_2016_tract.csv")
```



<div style="margin-bottom:25px;">
</div>
## **Data Wrangling** 
\

It is rare that the data set you download is in exactly the right form for data analysis.  For example, you might want to analyze just Yolo county neighborhoods. Or you might want to discard certain variables from the dataset to reduce clutter. Or you encounter missing data. 

In this lab, we won't have time to go through all of the methods and functions in R that are associated with the data wrangling process. We will cover more in later labs and many methods you will have to learn on your own given the specific tasks you will need to accomplish.  In the rest of this guide, we'll go through some of the basic data wrangling techniques using the functions found in the package **dplyr**, which was automatically installed and loaded when you brought in the **tidyverse** package.  These functions can be used for tibbles and regular data frames.

<div style="margin-bottom:25px;">
</div>
### **Selecting and renaming variables**
\

In practice, most of the data files you will download will contain variables you don't need. It is easier to work with a smaller dataset as it reduces clutter and clears up memory space, which is important if you are executing complex tasks on a large number of observations.  Use the command `select()` to keep variables by name.  Visually, we are doing this (taken from the RStudio [cheatsheet](http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf))  

<center>
![](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/subsetcols.png)

</center>


To see the names of variables in your dataset, use the `names()` command.  

```{r}
names(ca)
```

Let's keep *GEOID*, *NAME*, *variable*, and *estimate* from the *ca* dataset.

```{r}
select(ca, GEOID, NAME, variable, estimate)
```

A shortcut way of doing this is to use the `:` operator.  

```{r}
select(ca, GEOID:estimate)
```

The `:` operator tells R to select all the variables from *GEOID* to *estimate*.  This operator is useful when you've got a lot of variables to keep and they all happen to be ordered sequentially.

You can use also use `select()` command to keep variables *except* for the ones you designate.  For example, to keep all variables in *ca* except *moe* and save this into a new tibble called *ca1*, type in

```{r, results="hide"}
ca1 <- select(ca, -(moe))
```

The negative sign tells R to exclude the variable named within the parentheses. 

You will likely encounter a variable with a name that is not so descriptive.  Use the command `rename()` to, what else, rename a variable!  Let's rename *AF49E001* to *medincome* in the *nhgisfile1* dataset.  Make this permanent by assigning it back to *nhgisfile1* using the arrow operator `<-`

```{r}
nhgisfile1 <- rename(nhgisfile1, medincome = AF49E001)
names(nhgisfile1)
```

Note that you can rename multiple variables within the same `rename()` command.  

<div style="margin-bottom:25px;">
</div>                            
### **Tidy up**
\

Tidying up a dataset means following the rules outlined on page 149 of RDS: (1) Each variable must have its own column, (2) each observation must have its own row, and (3) each value must have its own cell. The dataset *nhgisfile1* looks "tidy", but the dataset *ca1* is not.  Why?

We'll need to "spread" the dataset. This will convert the dataset from long to wide.  Use the function `spread()` and save the tidy dataset back into *ca1*. 

```{r}
ca1 <- spread(ca1, key = variable, value = estimate)
ca1
```

Compare *ca1* and *ca*.  *ca* is a tract by variable level dataset whereas *ca* is a tract level dataset. Check the dimensions

```{r}
dim(ca)
dim(ca1)
```

<div style="margin-bottom:25px;">
</div>
### **Creating new variables**
\

The `mutate()` function allows you to create new variables within your dataset.  This is important when you need to transform variables in some way - for example, calculating a ratio or adding two variables together.  Visually, you are doing this

<center>
![](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/mutate.png)

</center>

You can use the `mutate()` command to generate as many new variables as you would like.  For example, let's construct four new variables in *ca1* - the percent of residents who are non-Hispanic white, non-Hispanic Asian, non-Hispanic black, and Hispanic.  Name these variables *pnhwhite*, *pnhasn*, *pnhblk*, and *phisp*, respectively.

```{r, results="hide"}
mutate(ca1, pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
              pnhblk = nhblk/tpopr, phisp = hisp/tpopr)
```

Note that you can create new variables based on the variables you just created in the same line of code. For example, you can create a categorical variable yielding "Majority" if the tract is majority Hispanic and "Not Majority" otherwise after creating the percent Hispanic variable within the same `mutate()` command.  Let's save these changes back into *ca1*.

```{r, results="hide"}
ca1 <- mutate(ca1, pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
              pnhblk = nhblk/tpopr, phisp = hisp/tpopr,
              mhisp = ifelse(phisp > 0.5, "Majority","Not Majority"))
ca1
```

We used the function `ifelse()` to create *mhisp* - the function tells R that if the condition `phisp > 0.5` is met, the tract's value for the variable *mhisp* will be "Majority", otherwise it will be "Not Majority".


<div style="margin-bottom:25px;">
</div>
### **Merging files**
\

We need to join the two datasets *nhgisfile1* and *ca1* together.  Remember from lecture that the unique Census ID for a tract combines the tract, county and state IDs.  We have this ID as the single variable GEOID in *ca1*, but separated as *STATEA*, *COUNTYA* and *TRACTA* in nhgisfile1.  See Figure 2.

<center>
![Figure 2: Geographic IDs](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/lab1fig3.png)

</center>


We can merge the two files by either merging on a single variable or on the two separate variables.  We just need to make sure it is consistent across the two datasets.  Let's combine *STATEA*, *COUNTYA* and *TRACTA* into a single variable so it will match *GEOID*.  To do this, use the command `str_c()` in the `mutate()` command.  This function concatenates (joins together) two or more character variables.

```{r}
nhgisfile1 <- mutate(nhgisfile1, GEOID = str_c(STATEA, COUNTYA, TRACTA))
```

The function `str_c()` concatenates.  There is also a function that separates, which is unsuprisingly named `separate()`.  The function separates a character variable based on [delimiters](https://en.wikipedia.org/wiki/Delimiter).  The variable *NAME* in *ca1* combines census tract name, county, and state.  Let's use `separate()` to separate this variable into its three separate parts.

```{r}
ca1 <- separate(ca1, col = NAME, into = c("Tract", "County", "State"), sep = ", ")
```

In the `separate()` function, you specify the variable or column you want to separate (`col = NAME`), the names of the three new variables containing the separate data pieces (`into = c("Tract", "County", "State")`), and the delimiter, which is a comma with a space (`sep = ", "`).

To merge the two datasets together, we'll use the function `left_join()`, which matches pairs of observations whenever their keys are equal. We match on the variable *GEOID* and save the merged data set into a new object called *cacounty*.

```{r}
catracts <- left_join(ca1, nhgisfile1, by = "GEOID")
```

Remember that *nhgisfile1* contains data on all U.S. tracts.

```{r}
dim(nhgisfile1)
```

The resulting join merges the variables from *nhgisfile1* **into** *ca1*. As such, *catracts* should only contain California tracts. You can check by examining the dimensions of *ca1* and *catracts* - the number of rows should be equal.

```{r}
dim(catracts)
dim(ca1)
```

There are other types of joins, which you can read more about in Chapter 10 of RDS.

Let's keep a dataset containing race/ethnicity, median household income and some essential ID variables.

```{r}
catracts <- select(catracts, GEOID, County, COUNTYA, pnhwhite:mhisp, medincome)
```


<div style="margin-bottom:25px;">
</div>
### **Pipes**
\

One of the important innovations from the tidy verse is the pipe operator `%>%`.  You use the pipe operator when you want to combine mutiple operations into one line of code.  For example, in cleaning the data set *ca*, we had two lines of code that (1) eliminate the variable *moe* and (2) made the data set tidy friendly.  A pipe allows us to do this in one line of code

```{r eval = FALSE}
ca2 <- ca %>% 
      select(-(moe)) %>% 
      spread(key = variable, value = estimate) 
```

Let's break down what the pipe is doing here.  First, you start out with your dataset *ca*.  You "pipe" that into the command `select()`.  Notice that you didn't have to type in *ca* inside that command - `%>%` pipes that in for you.  `select()` deletes *moe* and then pipes this result into the command `spread()`, which converts the data from long to wide.  Finally, the code saves the result into *ca2* which we designated at the beginning with the arrow operator.  

The pipe operator is very useful for complex operations, which you will encounter in the coming weeks.  From now on, we'll be using the pipe operator to make our code more efficient.

<div style="margin-bottom:25px;">
</div>
### **Subsetting/Filtering**
\

Subsetting or filtering means selecting rows/obsevervations based on their values.  To subset in R, use the command `filter()`.  Visually, subsetting rows looks like.

<center>
![](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/subsetrows.png)

</center>

The first argument in the parentheses of this command is the name of the data frame. The second and any subsequent arguments (separated by commas) are the expressions that filter the data frame. For example, we can select Sacramento county using its [FIPS code](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/ca/home/?cid=nrcs143_013697)

```{r, results="hide"}
filter(catracts, COUNTYA == "06067")
```

The double equal operator `==` means equal to.  We can also explicitly exclude cases and keep everything else by using the not equal operator `!=`.  The following code *excludes* Sacramento county.

```{r, results="hide"}
filter(catracts, COUNTYA != "06067")
```


What about filtering if a county has a value greater than a specified value?  For example, counties with a percent white greater than 0.5 (50%). 

```{r, results="hide"}
filter(catracts, pnhwhite > 0.50)
```

What about less than 0.5 (50%)?

```{r, results="hide"}
filter(catracts, pnhwhite < 0.50)
```

Both lines of code do not include counties that have a percent white equal to 0.5.  We include it by using the less than or equal operator `<=` or greater than or equal operator `>=`.

```{r, results="hide"}
filter(catracts, pnhwhite <= 0.5)
```

In addition to comparison operators, subsetting may also utilize logical operators that make multiple selections.  There are three basic logical operators: `&` (and), `|` is (or), and `!` is (not).  We can keep counties with *pnhwhite* greater than 0.5 **and** *medincome* greater than $80,000 using `&`.

```{r, results="hide"}
filter(catracts, pnhwhite > 0.5 & medincome > 80000)
```

Use `|` to keep counties with a *COUNTYA* of "06067" (Sacramento) **or** "06113" (Yolo) **or** "06075" (San Francisco)

```{r, results="hide"}
sub.tracts <- filter(catracts, COUNTYA == "067" | COUNTYA == "113" | COUNTYA == "075")
```

<div style="margin-bottom:25px;">
</div>
## **Summarizing variables**
\

We now move from functions that help bring in and clean your data set to those that help summarize its variables.  We use the function `summarize()` to get descriptive statistics of our data.  For example, let's calculate mean neighborhood income in San Franciso, Yolo, and Sacramento counties. The first argument inside `summarize()` is the data object ncal.tracts and the second argument is the function calculating the specific summary statistic, in this case `mean()`.

```{r}
summarize(sub.tracts, mean(medincome))
```


<center>
![](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/11swwp.jpg)

</center>


We got an NA.  This means we have missing median household income for at least one of our tracts.  I've uploaded a [tutorial]() for dealing with missing data.  The methods I suggest are *basic* - one can teach an entire class on missing data - so keep this in mind when you deal with missing data in your projects.  Please read through the tutorial on your own time.  For now, let's use the `na.rm = TRUE` argument, which removes tracts that are missing median household income.

```{r}
summarize(sub.tracts, mean(medincome, na.rm = TRUE))
```


Does the average neighborhood income differ by county? We need to pair `summarize()` with the function `group_by()` to answer this question. The function `group_by()` tells R to run subsequent functions on the data object by a group characteristic (such as gender, educational attainment, or in this case, county).  We'll need to use our new best friend `%>%` to accomplish this task

```{r}
sub.tracts %>%
  group_by(County) %>%
  summarize(mean(medincome, na.rm=TRUE))
```

The first pipe sends sub.tracts into the function `group_by()`, which tells R to group *sub.tracts* by the variable *County*.

How do you know the tibble is grouped? Because it tells you


<center>
![](/Users/noli/Documents/UCD/teaching/CRD 230/Lab/crd230.github.io/lab1fig4.png)

</center>


The second pipe takes this grouped dataset and sends it into the `summarize()` command, which calculates the mean neighborhood income (by county, because the dataset is grouped by county).

We can calculate more than one summary statistic within `summarize()`. For example, to get the mean, median and standard deviation of median income, its correlation with percent Hispanic, and give column labels for the variables in the resulting summary table, we type in

```{r}
sub.tracts %>%
  group_by(County) %>%
  summarize(incmn = mean(medincome, na.rm=TRUE),
            incmd = median(medincome, na.rm=TRUE),
            incsd = sd(medincome, na.rm=TRUE),
            corhispinc = cor(medincome, phisp, use = "complete"))
```

We usually summarize categorical variables by examining a frequency table.  To get the percent of tracts that have a majority Hispanic population, you’ll need to combine the functions `group_by()`, `summarize()` and `mutate()` using %>%.

```{r}
sub.tracts %>%
  group_by(mhisp) %>%
  summarize(n = n()) %>%
  mutate(freq = n / sum(n))
```

The code `group_by(mhisp)` separates the neighborhoods by the categories of *mhisp* (Majority, Not Majority - there are two tracts with missing values).  We then used `summarize()` to count the number of neighborhoods that are Majority and Not Majority. The function to get a count is `n()`, and we saved this count in a variable named *n*.

Next, we used `mutate()` on this table to get the proportion of all neighborhoods by Majority Hispanic designation. The code sum(n) adds the values of n. We then divide the value of each *n* by this sum. That yields the final frequency table.

We can add city to the group_by() function to disaggregate by County. Let's remove tracts with a missing value for *mhisp* using the `filter()` command

```{r}
sub.tracts %>%
  filter(is.na(mhisp) == FALSE) %>%
  group_by(County, mhisp) %>%
  summarize (n = n()) %>%
  mutate(freq = n / sum(n))
```



<div style="margin-bottom:25px;">
</div>
## **Summarizing variables using graphs**
\

Another way of summarizing variables and their relationships is through graphs and charts.  The main package for R graphing is **ggplot2** which is a part of the **tidyverse** package.  The graphing function is `ggplot()` and it takes on the basic template

`````r ''`
ggplot(data = <DATA>) +
      <GEOM_FUNCTION>(mapping = aes(x, y))
````

* `ggplot()` is the base function where you specify your dataset using the `data = <DATA>` argument.  
* You then need to build on this base by using the plus operator `+` and `<GEOM_FUNCTION>()` where `<GEOM_FUNCTION>()` is a unique function indicating the type of graph you want to plot. For example, the `<GEOM_FUNCTION>()` for a histogram is `geom_histogram()`.
* Each unique function has its unique set of mapping arguments which you specify using the `mapping = aes()` argument.  Charts and graphs have an x-axis, y-axis, or both.  


A typical visual for summarizing a numeric variable is a histogram. To create a histogram, use `geom_histogram()` for `<GEOM_FUNCTION()>`. Let’s create a histogram of median household income.

```{r}
sub.tracts %>% 
  ggplot() + 
  geom_histogram(mapping = aes(x=medincome), na.rm = TRUE)
```  


We can use a boxplot to visually summarize the distribution of a single variable or the relationship between a categorical and numeric variable. Use geom_boxplot() for <GEOM_FUNCTION()> to create a boxplot. Let’s examine median household income.

```{r}
sub.tracts %>%
  ggplot() +
     geom_boxplot(mapping = aes(y = medincome), na.rm = TRUE)
```     
     

Let's check the distribution of median income by *mhisp*. Because we are examining the association between two variables, we need to specify x and y variables. The `geom_boxplot()` won't eliminate the NA values from *mhisp*, so we'll have to use the `filter()` command to remove them manually 

```{r}
sub.tracts %>%
  filter(is.na(mhisp) == FALSE) %>%
  ggplot() +
    geom_boxplot(mapping = aes(x = mhisp, y = medincome), na.rm = TRUE)
```

The boxplot is for all neighborhoods combined. Use the `facet_wrap()` function to separate by County

```{r}
sub.tracts %>%
  filter(is.na(mhisp) == FALSE) %>%
  ggplot() +
  geom_boxplot(mapping = aes(x = mhisp, y = medincome), na.rm = TRUE) +
  facet_wrap(~County) 
```

`ggplot()` is a powerful function, and you can make a lot of really visually captivating graphs. You can also make maps with the function, which we'll cover in next week's lab.  We have just scratched the surface of its functions and features.  The list of all possible plots for `<GEOM_FUNCTION>()` can be found [here](https://ggplot2.tidyverse.org/reference/).  You can also make your graphs really "pretty" and professional looking by altering graphing features, including colors, labels, titles and axes.  For a list of `ggplot()` functions that alter various features of a graph, check out [Chapter 22 in RDS](http://r4ds.had.co.nz/graphics-for-communication.html). 


***


Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)
