---
title: "Geographically Weighted Regression"
subtitle: <h4 style="font-style:normal">CRD 298 - Spatial Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    code_folding: show
    mathjax: local
    self_contained: false
---


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

h1.title {
  font-weight: bold;
}

</style>
\

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


If we are interested in the influence or effect of some variable $x$ on another variable $y$, we run a regression model.  If $y$ is continuous, this model typically takes on the following form

$$y = \beta_0 + \beta_1 x + \varepsilon$$

The coefficient $\beta_1$ represents the increase in $y$ due to a one-unit increase in $x$. This equation represents a global model, and $\beta_1$ is applied to all spatial units in the study area.

The assumption is that the relationship between $x$ and $y$ is stationary.  Stationarity is a general term in statistics, generally it means that something doesn't change over time or space.   In spatial statistics, stationarity equals the homogeneity of an effect, or, that a process works the same regardless of where you observe the process. This can can be a weak assumption, and we can ask, does $x$ affect $y$ differently at different geographic locations, or in terms of parameters: If we estimate that  $\beta_1$ = $\sigma$, are there locations in the data where $\beta_1$ does not equal $\sigma$?

In prior lab guides, we went through methods that explore and measure the unequal spatial distribution of a variable $x$.  For example, we used Moran's I to measure global and local measures of spatial autocorrelation.  In this lab guide, we will examine the unequal spatial distribution in the *relationship* between two variables $x$ and $y$.  The method we will cover in this guide that captures this spatial heterogeneity is Geographically Weighed Regression (GWR).  

<div style="margin-bottom:25px;">
</div>
## **Install and load necessary packages**
\

We'll be introducing the following package in this lab 

```{r eval = FALSE}
install.packages("spgwr")
```

Load in the following packages

```{r warning = FALSE, message = FALSE}
library(sp)
library(spdep)
library(sf)
library(tmap)
```


<div style="margin-bottom:25px;">
</div>
## **Bring in the data**
\

We will be using the shapefile phil_tracts.shp.  The file contains major building code violation rates at the census tract level in the City of Philadelphia.  The file also contains demographic and socioeconomic neighborhood characteristics.  The record layout can be found [here](https://raw.githubusercontent.com/crd230/data/master/ph_tract_record_layout.txt).

I zipped up the files associated with the shapefile onto Github.  Download the file, unzip it, and bring it into R using the following code.

```{r warning = FALSE, message = FALSE, eval = FALSE}
setwd("insert your pathway here")
download.file(url = "https://raw.githubusercontent.com/crd230/data/master/phil_tracts.zip", destfile = "phil_tracts.zip")
unzip(zipfile = "phil_tracts.zip")

philly <- st_read("phil_tracts.shp")
```

```{r warning = FALSE, message = FALSE, include = FALSE}
download.file(url = "https://raw.githubusercontent.com/crd230/data/master/phil_tracts.zip", destfile = "phil_tracts.zip")
unzip(zipfile = "phil_tracts.zip")

philly <- st_read("phil_tracts.shp")
```


<div style="margin-bottom:25px;">
</div>
## **Ordinary Least Squares Regression**
\

We want to examine the relationship between neighborhood characteristics and major building code violation rates.  Let's run a basic Ordinary Least Squares (OLS) regression of number of major building code violations per area in square miles (*usarea*) on the following independent variables: Log median household income, log population size, percent non-Hispanic black, percent Hispanic, the unemployment rate, percent vacant units, percent of housing units built before 1970, percent of housing units built 2014 and after, and log median housing value. 

```{r}
fit.ols<-glm(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + lmhval + 
     phnew + phisp, data = philly) 
summary(fit.ols)
```

We find that the percent of vacant units is positively associated with the number of major building code violations per square mile, whereas the percent of units built before 1970 and log median housing value are negatively associated.  This model assumes spatial homogeneity in these relationships.  Let's examine whether this assumption of homogeneity is appropriate by running a GWR.

<div style="margin-bottom:25px;">
</div>
## **Geographically Weighted Regression**
\

First proposed by Brundson et al. (1996), the GWR estimates $\beta_p$  at each location $i$, using the centroids for polygon data. The model takes on the following form

$$y_i = \beta_{i0} + \beta_{i1} x_{i1} + ...  \beta_{ip} x_{ip}  + \varepsilon_{i}$$

where $\beta_{ip}$  is the local realization of $\beta_p$  at location $i$. This constructs a trend surface of parameter values for each independent variable and the model intercept.

GWR is an outgrowth of ordinary least squares regression (OLS); and adds a level of modeling sophistication by allowing the relationships between the independent and dependent variables to vary by locality.  Note that the basic OLS regression model above is just a special case of the GWR model where the coefficients are constant over space. The parameters in the GWR are estimated by weighted least squares. The weighting matrix is a diagonal matrix, with each diagonal element $w_{ij}$ being a function of the location of the observation.  The role of the weight matrix is to give more value to observations that are close to $i$, as it is assumed that observations that are close will influence each other more than those that are far away (Tobler's Law). 

There are three major decisions to make when running a GWR: (1) the kernel density function assigning weights $w_{ij}$, (2) the bandwidth $h$ of the function, which determines the degree of distance decay, and (3) who to count as neighbors.

<div style="margin-bottom:25px;">
</div>
### **Kernel density function and bandwidth h**
\

The kernel density function determines the weight assigned to neighboring units.  A common density function is a Gaussian weighting function

\[
w_{ij} = exp(-\frac{d_{ij}^2}{h^2})
\]


where $d_{ij}$ is the distance between location $i$ and $j$ and $h$ is the bandwidth.

Other common density functions include an Exponential function

$$w_{ij} = exp(-\frac{d_{ij}}{h})$$

a bi-square function

$$w_{ij} = 1-(\frac{d_{ij}^2}{h^2})^2$$

and a tri-cube function

$$w_{ij} = 1-(\frac{d_{ij}^3}{h^3})^3$$

Choosing a weighting function also involves choosing a bandwidth *h*.  There are several ways to do this.  R uses two methods.  The first uses a cross-validation method to choose the optimal kernel bandwidth. The cross validation method takes the form

$$CV = \sum_i \left[y_i - \hat{y}_{\neq i}(\beta)\right]^2$$

where $\hat{y}_{\neq i}(\beta)$ is the fitted value of $y_i$ with the observations for point $i$ omitted from the calibration process. Here, were trying to find the $h$ that minimizes $CV$.  This in effect minimizes the sum of squared errors at all locations $i$, and arrives at an optimal bandwidth.  The other method chooses a bandwidth the minimizes the Akaike Information Criterion (AIC).

To run a GWR, you need to load in the packages **spgwr**

```{r warning = FALSE, message = FALSE}
library(spgwr)
```

You also need to turn *philly* into an sp object.

```{r}
philly.sp <- as(philly, "Spatial")
```

In order to calculate an optimal bandwidth in R, use the command `gwr.sel()`.  The default method is cross-validation

```{r warning = FALSE, message = FALSE, results = "hide"}
gwr.b1<-gwr.sel(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + 
                  lmhval + phnew + phisp, philly.sp)
```

Let's see what the the estimated optimal bandwidth is.

```{r}
gwr.b1
```

This is the distance (in meters, because our data are projected in a system measured in meters), which the weighting function will search, and include all observations within this radius. This also represents your value $h$. Look at the R help file for `gwr.sel()` to determine how to change the selection method from minimizing CV to minimizing AIC.`

Plug the bandwidth into the function `gwr()`, which runs the GWR model, using the argument `bandwidth`

```{r warning = FALSE, message = FALSE, results = "hide"}
gwr.fit1<-gwr(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + lmhval + 
     phnew + phisp, data = philly.sp, bandwidth = gwr.b1, se.fit=T, hatmatrix=T)
```

Don't use `summary()` for a GWR object.  Just type the object name and you will get back the relevant summary information for the model.

```{r}
gwr.fit1
```

We'll go through the summary output later in the guide.  The default weighting function is the Gaussian function, which we can change to a bi-square function through the `gweight` argument.  We have to specify this function in both estimating the optimal bandwidth and running GWR

```{r warning = FALSE, message = FALSE, results = "hide"}
gwr.b2<-gwr.sel(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + lmhval + 
     phnew + phisp, data = philly.sp, gweight = gwr.bisquare)

gwr.fit2<-gwr(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + lmhval + 
     phnew + phisp, data = philly.sp, bandwidth = gwr.b2, gweight = gwr.bisquare, se.fit=T, 
     hatmatrix=T)
```

And the results 

```{r warning = FALSE, message = FALSE}
gwr.b2
gwr.fit2
```

<div style="margin-bottom:25px;">
</div>
### **Fixed or adaptive kernel**
\

The GWR models we ran above yielded  a fixed distance to search for neighbors to include in the local regression. But there are places in our data where tracts are more densely occurring.  This means that in some areas, specifically in downtown Philadelphia, you'll include a larger number of neighboring tracts in the local regression compared to other areas, such as large tracts on the periphery of the city's boundaries. In this case, an adaptive kernel is suitable.  Figure 5 in Week 8's handout shows the differences between a fixed and adaptive kernel function.  In the left graphic, the regressions include different number of observations because the left area is more dense than the right.  In contrast, the adaptive kernel narrows in the left graphic in order to capture an equal number of observations.

In order to specify an adaptive kernel, specify `adapt = TRUE` when finding the optimal bandwidth using `gwr.sel()`.

```{r warning = FALSE, message = FALSE, results = "hide"}
gwr.b3<-gwr.sel(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + 
                  lmhval + phnew + phisp, data = philly.sp, adapt = TRUE)
```

We get the value

```{r}
gwr.b3
```

This value is the proportion of all cases which the weighting function will search, and include this fraction of observations in a model for each tract.   The bandwidth distance will change according to the spatial density of features in the input feature class. The bandwidth becomes a function of the number of nearest neighbors such that each local estimation is based on the same number of features. Instead of a specific distance, the number of neighbors used for the analysis is reported.

Plug the bandwidth into the function `gwr()`, which runs the GWR model, using the argument `adapt`

```{r warning = FALSE, message = FALSE}
gwr.fit3<-gwr(usarea ~ lmhhinc   + lpop + pnhblk + punemp + pvac  + ph70 + lmhval + 
     phnew + phisp, data = philly.sp, adapt=gwr.b3, se.fit=T, hatmatrix=T)
```


<div style="margin-bottom:25px;">
</div>
### **Presenting GWR results**
\

When presenting results of a GWR, you want to first show the distribution of coefficients for each variable.  You'll also want to present the estimates of the global model.   Typing in *gwr.fit3*  in R gives you this information, specifically the minimum, 25th percentile, median, 75th percentile, and maximum values of each variable's coefficients, along with the global regression coefficients and measures of model fit.

```{r warning = FALSE, message = FALSE}
gwr.fit3
```

The object *gwr.fit3* is a gwr object.  The object contains a number of other objects.  For example, typing in `gwr.fit3$results` gives you overall model results such as the AIC.  Typing in `gwr.fit3$bandwidth` gives you the bandwidth values for each of the 376 tracts in the dataset.  The fixed bandwidth object instead yields just one value which is the bandwidth used for all tracts

```{r warning = FALSE, message = FALSE}
gwr.fit1$bandwidth
```

Compared to

```{r warning = FALSE, message = FALSE, results = "hide"}
gwr.fit3$bandwidth
```

Plot this bandwidth and you'll find that smaller bandwidths are in smaller tracts primarily located in downtown Philadelphia.

```{r warning = FALSE, message = FALSE}
philly$bwadapt <- gwr.fit3$bandwidth

tm_shape(philly, unit = "mi") +
  tm_polygons(col = "bwadapt", style = "quantile",palette = "Reds", 
              border.alpha = 0, title = "") +
  tm_scale_bar(breaks = c(0, 1, 2), size = 1, position = c("right", "bottom")) +
  tm_compass(type = "4star", position = c("left", "top")) + 
  tm_layout(main.title = "GWR bandwidth",  main.title.size = 0.95, frame = FALSE, legend.outside = TRUE)
```

One item within the gwr object is called SDF and this is the spatial polygons data frame containing the 376 regression model estimates.  Get the names of the objects within SDF

```
names(gwr.fit3$SDF)
```

The variables *X.Intercept.* to *phisp* give the regression coefficients.  *X.Intercept.se* to *phisp_se* give the coefficient standard errors.  

In addition to mapping coefficient sizes, you should also map whether these coefficients are statistically significant.  Unfortunately, R doesn't have that information neatly compiled for you.  But, you can use the coefficient size and standard error to get a t-statistic, which you can then map onto a t distribution to find the pvalue.  Specifically, when testing $H_0: \hat{\beta}_p = 0$ against the alternative $H_1: \hat{\beta}_p \neq 0$, one assesses the magnitude of the $t$ ratio

Under the null hypothesis, the $t$ ratio follows a $t$ distribution, and hence one can calculate the probability.  To do this in R, first get the degrees of freedom from the gwr results object

```{r warning = FALSE, message = FALSE}
dfree<-gwr.fit3$results$edf
```

Next, calculate the *t* ratio.  Save this in your spatial data frame.  Let's do this for the variable *pnhblk* 

```{r warning = FALSE, message = FALSE}
philly$pnhblk.t <- gwr.fit3$SDF$pnhblk/gwr.fit3$SDF$pnhblk_se
```

Next, calculate the pvalue using the `pt()` command (type in `? pt` to see what this command is doing).  You'll have to multiply the value by 2 to get a two-tail *t* test

```{r warning = FALSE, message = FALSE}
philly$pnhblk.t.p<-2*pt(-abs(philly$pnhblk.t), dfree)
```

You can map the pvalue 

```{r warning = FALSE, message = FALSE}
breaks <- c(0,0.01,0.05,0.1,1)

tm_shape(philly, unit = "mi") +
  tm_polygons(col = "pnhblk.t.p",palette = "Reds", breaks = breaks,
              border.alpha = 0, title = "") +
  tm_scale_bar(breaks = c(0, 1, 2), size = 1, position = c("right", "bottom")) +
  tm_compass(type = "4star", position = c("left", "top")) + 
  tm_layout(main.title = "t-stat",  main.title.size = 0.95, frame = FALSE, legend.outside = TRUE)
```
  
What are the results suggesting about the spatial heterogeneity of the relationship between percent black and major building code violations?

<div style="margin-bottom:25px;">
</div>
## **Multicollinearity**
\

GWR builds a local regression equation for each feature in the dataset. When the values for a particular explanatory variable cluster spatially, you will very likely have problems with local multicollinearity.  This is also a problem when sample sizes are small (Wheeler 2007). Consequences of local collinearity include estimated regression coefficients with increased magnitude and counterintuitive signs, inflated variances of regression coefficients, and insignificant statistical test values

One way to gauge the degree of multicollinearity is to examine correlations between the coefficients produced by the GWR.  To do this in R, use the `cor()` command

```{r warning = FALSE, message = FALSE}
round(cor(as.data.frame(gwr.fit3$SDF[,2:11]), use ="complete.obs"),2)
```

You check correlations visually by using the `pairs()` command

```{r warning = FALSE, message = FALSE}
pairs(as(gwr.fit3$SDF, "data.frame")[,2:11], pch=".")
```

It is recommended that researchers do model selection and diagnosis as part of their analyses when using GWR in order to avoid or reduce multicollinearity (Wheeler and Tiefelsdorf 2005).

<div style="margin-bottom:25px;">
</div>
## **Model fit**
\


I don't believe a GWR should take precedence over a traditional OLS or any of the spatial regression models we covered in class.  That is, a GWR is a nice method to supplement traditional global models, but should not be considered an inferential tool in the same way that global models can be.  Nevertheless, we can still compare the "fit" of a GWR relative to an OLS or any other regression model.

One way of doing this is to compare AIC values.  The GWR output offers three different ways to measure AIC.

```{r warning = FALSE, message = FALSE}
gwr.fit3$results$AICh

gwr.fit3$results$AICc

gwr.fit3$results$AICb
```

Compare these AICs to the OLS AIC

```{r warning = FALSE, message = FALSE}
AIC(fit.ols)
```


The downside of the AIC is that it offers no inferential way of detecting whether differences are statistically different from one another.  The package **spgwr** has a suite of tests comparing OLS and GWR models under an inferential framework.  These tests are described in Fotheringham et al. (2002).  The null in these tests is the OLS and thus a statistically significant test statistic indicates that the GWR provides a statistically significant improvement over an OLS in terms of its ability to match observed values.  The tests in R code are as follows

```{r warning = FALSE, message = FALSE}
BFC02.gwr.test(gwr.fit3)

BFC99.gwr.test(gwr.fit3)

LMZ.F1GWR.test(gwr.fit3)

LMZ.F2GWR.test(gwr.fit3)

LMZ.F3GWR.test(gwr.fit3)
```

The first 4 tests compare overall model fit whereas the last test examines spatial variation in individual coefficients.  All 4 overall model fit tests show that the GWR shows significant improvement in explanatory power over an OLS.  The last model shows that the variables *pvac*, *phnblk*, and *ph70* indicate statistically significant spatial heterogeneity in its GWR coefficients. These results indicate that there is spatial heterogeneity in the relationships between our covariates and major build code violations.  Look at the distribution of the GWR coefficients for *pvac*, *phnblk*, and *ph70* to see the range of variation between the local coefficients.


***


Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)